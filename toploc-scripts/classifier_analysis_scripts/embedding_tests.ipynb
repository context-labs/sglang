{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALGO = \"cosine/all-MiniLM-L6-v2\"\n",
    "# ALGO = \"cosine/all-mpnet-base-v2\"\n",
    "ALGO = \"cosine/distiluse-base-multilingual-cased-v1\"\n",
    "# ALGO = \"cross-encoder/ms-marco-MiniLM-L12-v2\"\n",
    "# ALGO = \"cross-encoder/stsb-roberta-large\"\n",
    "# ALGO = \"dot/msmarco-bert-base-dot-v5\"\n",
    "\n",
    "TEST = \"DETECT_QUANTIZATION_SPOOF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown, display_markdown\n",
    "from perform_embedding_based_replication_v1 import (\n",
    "    compute_scores,\n",
    "    make_sim_callback,\n",
    "    create_data_subsets,\n",
    "    plot_roc_curve,\n",
    "    plot_score_histogram,\n",
    "    calculate_roc_metrics,\n",
    "    write_summary,\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "N = None\n",
    "sim_callback = make_sim_callback(ALGO)\n",
    "\n",
    "df = []\n",
    "replications_dir = os.path.join(\"..\", \"replications\")\n",
    "for filename in os.listdir(replications_dir):\n",
    "    filepath = os.path.join(replications_dir, filename)\n",
    "    data = json.load(open(filepath, \"r\"))\n",
    "    compute_scores(N, sim_callback, data, df)\n",
    "df = pd.DataFrame(df)\n",
    "df[\"count\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"meta-llama/Llama-3.1-8B-Instruct\" \"context-labs/neuralmagic-llama-3.1-8b-instruct-FP8\" \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "_3_1_8B_FP16 = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "_3_1_8B_FP8 = \"context-labs/neuralmagic-llama-3.1-8b-instruct-FP8\"\n",
    "_3_2_3B_MODEL = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "DIFFERENT_MACHINE_TEST = (df[\"inference_machine\"] == \"4090\") & (\n",
    "    df[\"replication_machine\"] == \"3090\"\n",
    ")  #\n",
    "DIFFERENT_QUANTIZATION_TEST = df[\"original_model\"].isin(\n",
    "    [_3_1_8B_FP16, _3_1_8B_FP8]\n",
    ") & df[\"replication_model\"].isin([_3_1_8B_FP16])\n",
    "DIFFERENT_MODEL_TEST = (df[\"original_model\"].isin([_3_1_8B_FP16, _3_2_3B_MODEL])) & (\n",
    "    df[\"replication_model\"].isin([_3_1_8B_FP16])\n",
    ")\n",
    "\n",
    "if TEST == \"DETECT_QUANTIZATION_SPOOF\":\n",
    "    name = \"Detect Quantization Spoofing\"\n",
    "    subset_df = df[DIFFERENT_MACHINE_TEST & DIFFERENT_QUANTIZATION_TEST]\n",
    "elif TEST == \"DETECT_MODEL_SPOOF\":\n",
    "    name = \"Detect Model Spoofing\"\n",
    "    subset_df = df[DIFFERENT_MACHINE_TEST & DIFFERENT_MODEL_TEST]\n",
    "else:\n",
    "    raise Exception(f\"Unknown TEST: {TEST}\")\n",
    "\n",
    "\n",
    "import importlib\n",
    "import perform_embedding_based_replication_v1 as mylib\n",
    "\n",
    "importlib.reload(mylib)\n",
    "\n",
    "display(Markdown(f\"{name} / {len(subset_df)}\"))\n",
    "score_column = \"similarity\"\n",
    "\n",
    "selected_threshold = None\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "mylib.plot_score_histogram(\n",
    "    subset_df, score_column, name, ax=ax, selected_threshold=selected_threshold\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "mylib.plot_roc_curve(df, score_column)\n",
    "plt.show()\n",
    "\n",
    "summary = mylib.write_summary(subset_df, score_column)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
